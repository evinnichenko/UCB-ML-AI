{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What drives the price of a car?\n",
    "\n",
    "![](images/kurt.jpeg)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**OVERVIEW**\n",
    "\n",
    "In this application, you will explore a dataset from kaggle. The original dataset contained information on 3 million used cars. The provided dataset contains information on 426K cars to ensure speed of processing.  Your goal is to understand what factors make a car more or less expensive.  As a result of your analysis, you should provide clear recommendations to your client -- a used car dealership -- as to what consumers value in a used car."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CRISP-DM Framework\n",
    "\n",
    "<center>\n",
    "    <img src = images/crisp.png width = 50%/>\n",
    "</center>\n",
    "\n",
    "\n",
    "To frame the task, throughout our practical applications we will refer back to a standard process in industry for data projects called CRISP-DM.  This process provides a framework for working through a data problem.  Your first step in this application will be to read through a brief overview of CRISP-DM [here](https://mo-pcco.s3.us-east-1.amazonaws.com/BH-PCMLAI/module_11/readings_starter.zip).  After reading the overview, answer the questions below."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Business Understanding\n",
    "\n",
    "From a business perspective, we are tasked with identifying key drivers for used car prices.  In the CRISP-DM overview, we are asked to convert this business framing to a data problem definition.  Using a few sentences, reframe the task as a data task with the appropriate technical vocabulary. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Customer wants to be able to predict prices for used cars. For this purpose, we need to find a set of features that have the most effect on the price and find exactly what this effect is."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Understanding\n",
    "\n",
    "After considering the business understanding, we want to get familiar with our data.  Write down some steps that you would take to get to know the dataset and identify any quality issues within.  Take time to get to know the dataset and explore what information it contains and how this could be used to inform your business understanding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, PolynomialFeatures, OrdinalEncoder\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.compose import ColumnTransformer\n",
    "import plotly.express as px\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression, Lasso, Ridge\n",
    "from sklearn.metrics import mean_squared_error, explained_variance_score\n",
    "import pickle\n",
    "from sklearn.linear_model import LinearRegression, Lasso\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy import stats\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (10, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cars = pd.read_csv(\"data/vehicles.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cars.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cars.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cars.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cars.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cars[\"condition\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cars[\"drive\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems that we have 4 numerical properties (id, which is not useful for our analysis, price, year, and odometer/mileage) and 13 text-based categorical properties, including VIN (which is useless for this analysis due to being unique identifier of a specific car).\n",
    "\n",
    "Now let's see how much of it is empty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_values = (cars.isna().mean() * 100).reset_index().rename(columns={\"index\": \"Features\", 0: \"Missing %\"})\n",
    "missing_values[\"Missing %\"] = round(missing_values[\"Missing %\"])\n",
    "missing_values[\"# of missing\"] = cars.isna().sum().to_frame().reset_index()[0]\n",
    "\n",
    "missing_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's check for duplicates\n",
    "cars.drop(\"id\", axis=1).duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cars[cars.drop([\"id\", \"VIN\"], axis=1).duplicated()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cars[cars[\"VIN\"].isna() == False].duplicated(['VIN']).sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "~56.2k duplicated rows, and 200 more that only differ in VIN. Speaking of which, there are 147.5 thousand (~34%) records of sells using same cars. Combined with 38% missing, this means that over 50% of this column is unusable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(cars[\"price\"])\n",
    "plt.title(\"\\n\\nBox Plot of Price\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vast majority of cars is sold at prices lower than 1M USD, typically around double digit thousands, but the box plot is heavily influenced by the outliers, going as high as 3.73 billion USD. Let's try removing them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cars_no_price_out = cars[(np.abs(stats.zscore(cars[\"price\"])) < 3)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cars_no_price_out = cars_no_price_out[(np.abs(stats.zscore(cars_no_price_out[\"price\"])) < 3)]\n",
    "cars_no_price_out = cars_no_price_out[(np.abs(stats.zscore(cars_no_price_out[\"price\"])) < 3)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cars_no_price_out.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(cars_no_price_out[\"price\"])\n",
    "plt.title(\"\\n\\nBox plot of prices, no outliers\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.box(cars_no_price_out[\"price\"], title=\"Box plot of prices, no outliers\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, after removing outliers (and doing it three times to get a good picture), most used car sales go between 0 and 56k, with middle 50% of sales in range between 5.8k and 26k USD.\n",
    "\n",
    "Now, let's do the same with odometer readings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(cars[\"odometer\"])\n",
    "plt.title(\"\\n\\nBox plot of odometer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cars_no_odometer_out = cars.dropna()[(np.abs(stats.zscore(cars[\"odometer\"].dropna())) < 3)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cars_no_odometer_out = cars_no_odometer_out[(np.abs(stats.zscore(cars_no_odometer_out[\"odometer\"])) < 3)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cars_no_odometer_out.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.box(cars_no_odometer_out[\"odometer\"], title = \"Box plot of odometer, no outliers\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most cars are sold with mileage between 0 and 253k miles (?), with middle 50% between 65k and 140k.\n",
    "\n",
    "Now let's see the distribution of various categorical properties."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cars_no_price_out[\"price\"].plot(kind=\"kde\")\n",
    "plt.title(\"KDE plot of price, no outliers\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cars_no_odometer_out[\"odometer\"].plot(kind=\"kde\")\n",
    "plt.title(\"KDE plot of odometer, no outliers\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's make some bulk plots for individual groups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [\"condition\", \"transmission\", \"drive\", \"title_status\", \"fuel\", \"cylinders\", \"type\"]\n",
    "fig, axs = plt.subplots(4, 2, figsize=(18, 15))\n",
    "counter = int(0)\n",
    "\n",
    "for i in features:\n",
    "    count = cars[i].value_counts().reset_index()\n",
    "    col1 = count.columns[0]\n",
    "    col2 = count.columns[1]\n",
    "    coordy = counter // 2\n",
    "    coordx = counter % 2\n",
    "    fig = sns.barplot(data=count, x=i, y=\"count\", ax=axs[coordy, coordx])\n",
    "    ax=axs[coordy, coordx].set_title(f'\\n\\nVolume per {i.title()}')\n",
    "    plt.xlabel(f\"{i.title()}\")\n",
    "    plt.ylabel(\"Count\")\n",
    "    counter = counter + 1\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = cars[\"title_status\"].value_counts().reset_index()\n",
    "col1 = count.columns[0]\n",
    "col2 = count.columns[1]\n",
    "fig = sns.barplot(data=count[count[\"title_status\"] != \"clean\"], x=\"title_status\", y=\"count\").set(title = '\\n\\nVolume per \"title_status\"')\n",
    "plt.xlabel(\"title_status\")\n",
    "plt.ylabel(\"Count\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some interesting finds here. Of course, most cars sold on used market run on gas, have 4/6/8 cylinder engines (as other types are very rare) in similar proportions, and have clean titles - and among relatively miniscule amount of other types, rebuilt and salvage titles come way ahead of lien or missing ones. Similarly, by now it is widely known that most of US aftermarket is taken by cars with automatic transmission. However, I find it unusual that number of \"good\" and \"excellent\" cars sold vastly exceeds that of \"new\" and \"like new\". Similarly surprising, at least for me, are relatively similar counts of 4WD and FWD cars, as well as volume of less popular body types like coupe and wagons - I expected them to be much lower."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_price = cars.groupby(['condition', \"transmission\", \"drive\", \"title_status\", \"fuel\", \"cylinders\", \"type\"])['price'].median().reset_index()\n",
    "\n",
    "fig, axs = plt.subplots(4, 2, figsize=(18, 15))\n",
    "\n",
    "sns.barplot(x='condition', y='price', data=total_price, ax=axs[0, 0])\n",
    "axs[0, 0].set_title('\\nAvg. price by condition')\n",
    "\n",
    "sns.barplot(x='transmission', y='price', data=total_price, ax=axs[0, 1])\n",
    "axs[0, 1].set_title('\\nAvg. price by tansmission')\n",
    "\n",
    "sns.barplot(x='drive', y='price', data=total_price, ax=axs[1, 0])\n",
    "axs[1, 0].set_title('\\n\\nAvg. price by type of drive')\n",
    "\n",
    "sns.barplot(x='title_status', y='price', data=total_price, ax=axs[1, 1])\n",
    "axs[1, 1].set_title('\\n\\nAvg. price by title status')\n",
    "\n",
    "sns.barplot(x='fuel', y='price', data=total_price, ax=axs[2, 0])\n",
    "axs[2, 0].set_title('\\n\\nAvg. price by fuel type')\n",
    "\n",
    "sns.barplot(x='cylinders', y='price', data=total_price, ax=axs[2, 1])\n",
    "axs[2, 1].set_title('\\n\\nAvg. price by number of cylinders')\n",
    "\n",
    "sns.barplot(x='type', y='price', data=total_price, ax=axs[3, 0])\n",
    "axs[3, 0].set_title('\\n\\nAvg. price by type of the car')\n",
    "\n",
    "plt.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A quick glance at average prices reveals some interesting conclusions. For example, type of transmission has very little effect on price of the car, while all other categories do have some - although it remains to be seen if it is direct influence or a consequence of another factor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cars.manufacturer.value_counts().sort_values(ascending=False).plot(kind=\"bar\", x=\"index\", y=\"manufacturer\")\n",
    "plt.title(\"Number of cars sold per manufacturer\")\n",
    "plt.xlabel(\"Manufacturer\")\n",
    "plt.ylabel(\"Count\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The big three names (>2.5k sold) in this dataset seem to be Ford, Chevrolet, and Toyota. After that we see end of large difference between adjacent manufacturers and instead number gradually decreases from just over 2000 sold (Honda) to miniscule amounts, like with Ferrari and Land Rover. Speaking of premium brands, we should check the prices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.box(cars, x=\"manufacturer\", y=\"price\", title=\"Box plot of price per manufacturer\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = \"images/manufacturer-price-box fixed scale.png\"/>\n",
    "\n",
    "*Above plot with scale adjusted to actually see the individual boxes*\n",
    "\n",
    "As you can see, while there are some severe outliers (surprisingly, most expensive individual cars were made by Toyota, Chevrolet, and Mercedes, Ford and Jeep getting some honorable mentions), for most manufacturers used cars go for about 5-30k USD, notable exceptions being Ferrari - 50% between 53-141k - and Aston-Martin, which can casually go for as much as 75 or even 180k."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(data=cars, x=\"condition\", order=cars[\"condition\"].value_counts().index)\n",
    "plt.title(\"Number of cars sold per condition\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected, people usually buy cars that are in decent condition, don't usually sell new or like new cars, and only rarely sell (or buy) salvage. Still, good thing to take a look at."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.box(cars, x=\"condition\", y=\"price\", title=\"Box plot of price per condition\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = \"images/condition-price-box fixed scale.png\"/>\n",
    "\n",
    "With some outliers, it is some surprise to see that cars in \"excellent\" and \"like new\" condition, as a rule, are sold cheaper than the ones in \"new\" and \"good\" conditions. Unsurprisingly, cars marked as \"fair\" and \"salvage\" are worth much less."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is also obvious that age of car plays a large role in the purchase decision. Let's see how exactly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.histogram(data_frame=cars, x=\"year\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_frame=cars[cars[\"year\"] > 2000][\"year\"].plot(kind=\"kde\")\n",
    "plt.title(\"KDE plot of year of manufacturing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cars_no_year_out = cars.dropna()[(np.abs(stats.zscore(cars[\"odometer\"].dropna())) < 3)]\n",
    "px.box(data_frame=cars_no_year_out, x=\"year\", y=\"price\", title=\"Price of cars per year\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well, it looks like this dataset was created in 2021 or 2022, and that people mostly buy cars that are up to 15 years old, with age being in a curious correlation with the price - for the first 30 years or so, higher age means lower price, but then car becomes retro and price grows with age."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Last two topics I wanted to touch are sales across states and different models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.histogram(data_frame=cars, x=\"state\", title=\"Number of cars sold per state\").update_xaxes(categoryorder='total descending')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.box(data_frame=cars, x=\"state\", y=\"price\", title=\"Price of cars per state\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = \"images/prices per state.png\"/>\n",
    "\n",
    "It seems that despite significant difference between number of cars sold per state (e.g. California), prices are more or less in line across the country, and even biggest upper fence outliers (e.g. Texas) are only different from other states by ~20k, or ~30%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.box(data_frame=cars, x=\"size\", y=\"price\", title=\"Price of cars per state\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = \"images/size-price-box fixed scale.png\"/>\n",
    "\n",
    "\n",
    "As we can see, size doesn't really affect price of the car. Tehre is some difference in full-size vs others, but it can just as easily be written off to this category also including trucks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cars_top15_models = cars.groupby(['model']).size().to_frame().sort_values([0], ascending = False).head(15).reset_index()\n",
    "px.histogram(data_frame=cars_top15_models, x='model', y=0, title=\"Top 15 used car models\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apparently, deciding to take a look at models was wrong due to how many there are. However, it is interesting to see that most resold cars are pickups (F-150, Silverado (regular and 1500), what I assume to be Ram 1500, Jeep Wrangler), as well as Asian everyday cars: Toyota Camry, Honda Civic and Accord, Nissan Altima."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cars_top15_models_prices = cars[[\"model\", \"price\"]]\n",
    "cars_top15_models_prices = cars_top15_models_prices.merge(cars_top15_models, on=\"model\")\n",
    "#.groupby(['model']).size().to_frame().sort_values([0], ascending = False).head(15).reset_index()\n",
    "\n",
    "cars_top15_models_prices.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.box(data_frame=cars_top15_models_prices, x='model', y=\"price\", title=\"Average price on Top 15 (by overall sales) used car models\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = \"images/model-price top15 fixed scale.png\"/>\n",
    "\n",
    "Here we can see (after some scaling to remove outliers) box charts for prices on the aforementioned top 15 models by nubmer of sales. interestingly, while there is some variation and tendencies - e.g. sedans seem to go for ~7k while trucks go for ~20k as their median prices - overall distinction is not so large as to be overall clear. Also, doing this requires some computing power and is not very reliable due to requiring data on *all* 29k models, many of which are not clearly defined: manually looking provided gems such as \"#NAME?\", \"150\" (no manufacturer), \"-3500\", \"1\" (again, no manufacturer. unlike with Mazda 3/6), years between 1990 and 2010 with no manufacturer, \"-\", \",2012,2013, SOME 2014 MODELS\", \".. ect.\", and variety of misapplied labels like providing all the info on the car (\"2011 f-450 4x4 crew cab in-closed utility\") or dividing (or not) different packages (e.g. standard and limited) into models of their own. Overall, while model *could* provide *some* information, it is not worth the effort."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.box(data_frame=cars, x=\"paint_color\", y=\"price\", title=\"Average price per color\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = \"images/color vs price.png\"/>\n",
    "\n",
    "\n",
    "As we can see, while color of the car might have some effect on its price (e.g. green cars sell cheaper than others), it is not enough of an effect to warrant using in this study."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preparation\n",
    "\n",
    "After our initial exploration and fine tuning of the business understanding, it is time to construct our final dataset prior to modeling.  Here, we want to make sure to handle any integrity issues and cleaning, the engineering of new features, any transformations that we believe should happen (scaling, logarithms, normalization, etc.), and general preparation for modeling with `sklearn`.\n",
    "\n",
    "**Convert number of cylinders to numeric**\n",
    "\n",
    "This step will make building models based on the number of cylinders easier and will bring electric cars into fold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting the Cylinder columns to numerical and replacing the 'other' with 0 since this will be applied to electric cars\n",
    "\n",
    "cars[\"cylinders\"] = cars[\"cylinders\"].str.replace(\"cylinders\", \"\")\n",
    "cars[\"cylinders\"] = cars[\"cylinders\"].str.strip()\n",
    "cars[\"cylinders\"] = cars[\"cylinders\"].str.replace(\"other\", \"0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Convert electric**\n",
    "\n",
    "Some of the cars on the list are electric. As such, they don't have any cylinders and use an \"other\" transmission. This step will ensure they all have this format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting the cylinders of electric cars to 0 \n",
    "\n",
    "cars.loc[cars[\"fuel\"] == \"electric\", \"cylinders\"] = cars.loc[cars[\"fuel\"] == \"electric\", \"cylinders\"].fillna(\"0\")\n",
    "\n",
    "# Converting transmission\n",
    "\n",
    "cars.loc[cars[\"fuel\"] == \"electric\", \"transmission\"] = cars.loc[cars[\"fuel\"] == \"electric\", \"transmission\"].str.replace(\"automatic\", \"other\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cars[\"cylinders\"] = cars[\"cylinders\"].astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Remove useless features**\n",
    "\n",
    "Some of the features have next to no effect on this study. As such, it will be better to delete them:\n",
    "\n",
    "- VIN stands for Vehicle Identification Number and is unique for each vehicle. Since it is only a bureaucratic property that has no real effect on purchase, it can be dropped immediately.\n",
    "- Model might provide some information, but with how much variation there is (29.5k models would require too much with encoding) and how misapplied this column is (see earlier about that), it is effectively useless. Same with the region.\n",
    "- Paint color has no noticeable effect on the car price\n",
    "- Manufacturer might have some effect, but with 42 different manufacturers it becomes too computationally expensive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cars = cars.drop([\"VIN\", \"model\", \"paint_color\", \"region\"], axis=1)\n",
    "#cars = cars.drop(\"manufacturer\", axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Remove outliers**\n",
    "\n",
    "Earlier, we found some boundaries for outliers in price and odometer readings. Now we will remove them manually based on the numbers found earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cars = cars.query(\"0 < price < 65_000\").copy()\n",
    "cars = cars.query(\"0 < odometer < 300_000\").copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Remove empty values**\n",
    "\n",
    "Initial data exploration revealed that many positions are filled with NaN. To provide better analysis, these need to be removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "#cars_drop = cars.dropna()\n",
    "#cars_drop.info()\n",
    "\n",
    "# Dropping Rows that have more than 10 columns as NaN\n",
    "\n",
    "cars_drop = cars.drop(cars[cars.isna().sum(axis=1) > 10].index)\n",
    "\n",
    "# Dropping the rows with Year NaN\n",
    "\n",
    "cars_drop.drop(cars_drop[cars_drop.year.isna()].index, inplace=True)\n",
    "\n",
    "# Dropping the rows with Manufacturer NaN\n",
    "\n",
    "cars_drop.drop(cars_drop[cars_drop.manufacturer.isna()].index, inplace=True)\n",
    "\"\"\"\n",
    "\n",
    "cars_drop = cars.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cars_drop.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Remove duplicates**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cars_drop = cars_drop[cars_drop.drop(\"id\", axis=1).duplicated() == False]\n",
    "cars_drop = cars_drop.drop_duplicates(subset=cars_drop.columns.drop(\"id\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cars_drop.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**OneHot Encoding**\n",
    "\n",
    "Finally, we will need to change categorical features into numerical with OneHot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummies=pd.get_dummies(cars_drop[['condition', 'fuel', 'title_status', 'transmission',\n",
    "                             'drive', 'size', 'type', \"state\", \"manufacturer\"]])\n",
    "cars_dummies = pd.concat([cars_drop, dummies], axis=1)\n",
    "cars_dummies=cars_dummies.drop(columns = ['condition', 'fuel', 'title_status', 'transmission',\n",
    "                             'drive', 'size', 'type', \"state\", \"manufacturer\"])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modeling\n",
    "\n",
    "With your (almost?) final dataset in hand, it is now time to build some models.  Here, you should build a number of different regression models with the price as the target.  In building your models, you should explore different parameters and be sure to cross-validate your findings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset\n",
    "y = cars_dummies[\"price\"]\n",
    "X = cars_dummies.drop(columns=\"price\")\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mse = []\n",
    "test_mse = []\n",
    "explained_variance = []\n",
    "model =[]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use several models: linear, polynomial, LASSO, and ridge regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear\n",
    "# Took just 1.6s to compute\n",
    "\n",
    "linear_model = Pipeline([\n",
    "    ('transform', PolynomialFeatures(degree=1, include_bias=False)),\n",
    "    ('scale', StandardScaler()),\n",
    "    ('linreg', LinearRegression())\n",
    "])\n",
    "linear_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Record MSE\n",
    "linear_train_mse= round(mean_squared_error(linear_model.predict(X_train), y_train), 4)\n",
    "linear_test_mse=round(mean_squared_error(linear_model.predict(X_test), y_test),4)\n",
    "linear_EV = explained_variance_score(y_train, linear_model.predict(X_train))\n",
    "\n",
    "train_mse.append(linear_train_mse)\n",
    "test_mse.append(linear_test_mse)\n",
    "explained_variance.append(linear_EV)\n",
    "model.append(\"Model 1 - linear\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Polynomial degree 2\n",
    "# Toom me 3m 51.5s to compute\n",
    "\n",
    "polynomial_model = Pipeline([\n",
    "    ('transform', PolynomialFeatures(degree=2, include_bias=False)),\n",
    "    ('scale', StandardScaler()),\n",
    "    ('linreg', LinearRegression())\n",
    "])\n",
    "polynomial_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Record MSE\n",
    "polynomial_train_mse= round(mean_squared_error(polynomial_model.predict(X_train), y_train), 4)\n",
    "polynomial_test_mse=round(mean_squared_error(polynomial_model.predict(X_test), y_test),4)\n",
    "polynomial_EV= explained_variance_score(y_train, polynomial_model.predict(X_train))\n",
    "\n",
    "train_mse.append(polynomial_train_mse)\n",
    "test_mse.append(polynomial_test_mse)\n",
    "explained_variance.append(polynomial_EV)\n",
    "model.append(\"Model 2 - polynomialDeg2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LASSO\n",
    "# Warning! This took me 16m 4s to compute\n",
    "\n",
    "lasso_model = Pipeline([\n",
    "    ('transform', PolynomialFeatures(degree=2, include_bias=False)),\n",
    "    (\"scaler\", StandardScaler()), \n",
    "    ('lasso', Lasso())\n",
    "])\n",
    "lasso_model.fit(X_train, y_train)\n",
    "\n",
    "lasso_coef = lasso_model.named_steps['lasso'].coef_\n",
    "lasso_coef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Record MSE\n",
    "lasso_train_mse= round(mean_squared_error(lasso_model.predict(X_train), y_train), 4)\n",
    "lasso_test_mse=round(mean_squared_error(lasso_model.predict(X_test), y_test),4)\n",
    "lasso_EV= explained_variance_score(y_train, lasso_model.predict(X_train))\n",
    "\n",
    "train_mse.append(lasso_train_mse)\n",
    "test_mse.append(lasso_test_mse)\n",
    "explained_variance.append(lasso_EV)\n",
    "model.append(\"Model 3 - LASSO\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ridge\n",
    "# Took me 5m 15.7s to compute\n",
    "\n",
    "ridge_model = Pipeline([\n",
    "    ('transform', PolynomialFeatures(degree=2, include_bias=False)),\n",
    "    ('scale', StandardScaler()),\n",
    "    ('ridge', Ridge())\n",
    "])\n",
    "\n",
    "alpha_value = {'ridge__alpha': [0.1,1,10]}\n",
    "\n",
    "model_finder = GridSearchCV(estimator = ridge_model, \n",
    "                           param_grid=alpha_value,\n",
    "                           scoring = \"neg_mean_squared_error\"\n",
    "                           )\n",
    "\n",
    "model_finder.fit(X_train, y_train)\n",
    "\n",
    "best_ridge_model=model_finder.best_estimator_\n",
    "best_alpha = model_finder.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Record MSE\n",
    "ridge_train_mse = round(mean_squared_error(best_ridge_model.predict(X_train), y_train),4)\n",
    "ridge_test_mse = round(mean_squared_error(best_ridge_model.predict(X_test), y_test),4)\n",
    "ridge_EV= explained_variance_score(y_train, best_ridge_model.predict(X_train))\n",
    "\n",
    "train_mse.append(ridge_train_mse)\n",
    "test_mse.append(ridge_test_mse)\n",
    "explained_variance.append(ridge_EV)\n",
    "model.append(\"Model 4 - Ridge\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ridge2**\n",
    "\n",
    "I had this idea of analyzing factors by themselves, but decided to do it by using another ridge model. There seems to be no other functional difference between the two"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making another X/y and Test/Train split due to this idea requiring non-OHE'd dataset\n",
    "\n",
    "y = cars_drop[\"price\"]\n",
    "X = cars_drop.drop(columns=\"price\")\n",
    "\n",
    "X_train2, X_test2, y_train2, y_test2 = train_test_split(X, y, random_state=42, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grabing the Object Columns for OneHotEncoding\n",
    "# Condition will be OrdinalEncoding, hence removing it from the list \n",
    "\n",
    "obj_cols = cars_drop.select_dtypes(\"object\").columns.to_list()\n",
    "\n",
    "obj_cols.remove('condition')\n",
    "obj_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using Ridge Regression \n",
    "\n",
    "alphas = np.linspace(0.1, 100, 50)\n",
    "\n",
    "randome_state = [10, 100]\n",
    "\n",
    "params = {\"ridge__alpha\": alphas, \"ridge__random_state\": randome_state}\n",
    "\n",
    "col_transformer = ColumnTransformer(transformers=[\n",
    "    ('ohe', OneHotEncoder(sparse_output=False), obj_cols),\n",
    "    (\"ord\", OrdinalEncoder(), ['condition']),\n",
    "    (\"poly\", PolynomialFeatures(degree=3, include_bias=False), [\"cylinders\", \"odometer\", \"year\"])\n",
    "])\n",
    "\n",
    "\n",
    "pipe = Pipeline([\n",
    "    (\"transformer\", col_transformer),\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"ridge\", Ridge())\n",
    "    ])\n",
    "\n",
    "grid_ridge = GridSearchCV(pipe, param_grid=params, cv=3, scoring=\"neg_mean_squared_error\", n_jobs=-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting\n",
    "\n",
    "grid_ridge.fit(X_train2, y_train2)\n",
    "best_model_ridge = grid_ridge.best_estimator_\n",
    "best_model_ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Record MSE\n",
    "ridge_train_mse2 = round(mean_squared_error(best_model_ridge.predict(X_train2), y_train2),4)\n",
    "ridge_test_mse2 = round(mean_squared_error(best_model_ridge.predict(X_test2), y_test2),4)\n",
    "ridge_EV2= explained_variance_score(y_train, best_model_ridge.predict(X_train2))\n",
    "\n",
    "train_mse.append(ridge_train_mse2)\n",
    "test_mse.append(ridge_test_mse2)\n",
    "explained_variance.append(ridge_EV2)\n",
    "model.append(\"Model 5 - Ridge2\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation\n",
    "\n",
    "With some modeling accomplished, we aim to reflect on what we identify as a high quality model and what we are able to learn from this.  We should review our business objective and explore how well we can provide meaningful insight on drivers of used car prices.  Your goal now is to distill your findings and determine whether the earlier phases need revisitation and adjustment or if you have information of value to bring back to your client."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MetricsTable = pd.DataFrame({\n",
    "    'model': model,\n",
    "    'train_mse': train_mse,\n",
    "    'test_mse':test_mse,\n",
    "    'explained_variance': explained_variance\n",
    "})\n",
    "\n",
    "MetricsTable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the table above, it is obvious that the best performing model is the Ridge model, and therefore is the one I will deploy.\n",
    "\n",
    "However, we can take this a step further and identify the most and least important factors in price of a car, which would be of much better immediate use to the business."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coefs = best_model_ridge.named_steps[\"ridge\"].coef_\n",
    "cols = best_model_ridge.named_steps.transformer.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#coef_features_df = pd.DataFrame({\"features\":cols, \"coefs\":np.abs(coefs)}).sort_values(by=\"coefs\", ascending=False)\n",
    "coef_features_df = pd.DataFrame({\"features\":cols, \"coefs\":coefs})#.sort_values(by=\"coefs\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.bar(coef_features_df, x=\"features\", y=\"coefs\", title=\"Coefficients of all Features\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have got coefficients for a bunch of internal features. Now we need to combine them into actual features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def break_OneHot_coefs(df, feature):\n",
    "    coef_df = df[df.features.apply(lambda x: feature in x)].copy()\n",
    "    coef_df.features = coef_df.features.str.replace(f\"ohe__{feature}_\", \"\")\n",
    "    coef_df.features = coef_df.features.str.title()\n",
    "    return {feature.title(): coef_df}\n",
    "\n",
    "def break_poly_coefs(df):\n",
    "    polycol = df[df.features.apply(lambda x: \"poly_\" in x)].copy()\n",
    "    polycol.drop(polycol[polycol.features.apply(lambda x: \"^\" in x)].index, inplace=True)\n",
    "    polycol.features = polycol.features.str.replace(f\"poly__\", \"\")\n",
    "    polycol.features = polycol.features.str.title()\n",
    "    return polycol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#man_coef_df = break_OneHot_coefs(coef_features_df, \"manufacturer\")\n",
    "type_coef_df = break_OneHot_coefs(coef_features_df, \"type\")\n",
    "fuel_coef_df = break_OneHot_coefs(coef_features_df, \"fuel\")\n",
    "title_coef_df = break_OneHot_coefs(coef_features_df, \"title_status\")\n",
    "transmission_coef_df = break_OneHot_coefs(coef_features_df, \"transmission\")\n",
    "drive_coef_df = break_OneHot_coefs(coef_features_df, \"drive\")\n",
    "state_coef_df = break_OneHot_coefs(coef_features_df, \"state\")\n",
    "\n",
    "#man_coef_df, \n",
    "all_coefs = [type_coef_df, fuel_coef_df, title_coef_df, transmission_coef_df, drive_coef_df, state_coef_df]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poly_cols = break_poly_coefs(coef_features_df)\n",
    "poly_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.bar(poly_cols, x=\"features\", y=\"coefs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(4, 2, figsize=(18, 15))\n",
    "counter = int(0)\n",
    "\n",
    "for i in all_coefs:\n",
    "    coordy = counter // 2\n",
    "    coordx = counter % 2\n",
    "\n",
    "    label = list(i.keys())[0]\n",
    "    dataframe = i[label]\n",
    "    fig = sns.barplot(data=dataframe, x=\"features\", y=\"coefs\", ax=axs[coordy, coordx])\n",
    "\n",
    "    plt.axhline(0, color='red', linestyle='--')\n",
    "    ax=axs[coordy, coordx].set_title(f'\\n\\n{label} Coefficients')\n",
    "    plt.xlabel(label)\n",
    "    plt.ylabel(\"Coefficients\")\n",
    "    counter = counter + 1\n",
    "\n",
    "plt.tight_layout()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deployment\n",
    "\n",
    "Now that we've settled on our models and findings, it is time to deliver the information to the client.  You should organize your work as a basic report that details your primary findings.  Keep in mind that your audience is a group of used car dealers interested in fine tuning their inventory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the end, we can find several regularities between features and price of the car:\n",
    "\n",
    "- Of manufacturers, Tesla, Toyota, Porsche, and Lexus have very good markup coefficients, as do some others like Mersedes, Audi, and Ram. more popular budget car manufacturers, like Nissan, Hyundai, Kia, and Mitsubishi are on the opposite, experiencing pretty severe negative markup. This is actually tied into the specific models, but that required too much outside information and wasn't analyzed.\n",
    "- Diesel usually sells for more money than other types, and gas cars are cheaper;\n",
    "- Of types, trucks, convertibles, and coupe are the ones with markup. Sedans, SUVs, and hatchbacks, on the other hand, are usually marked down;\n",
    "- Obviously, clean and lien cars sell for more than other title statuses. interestingly, offering a car as parts only is a good way to recuperate some of the loss if that is the only chance at selling it;\n",
    "- Manual transmission is more expensive, and \"other\" (IIRC, it was electrical) are much cheaper, but overall there is little change depending on transmission type;\n",
    "- 4WD cars are much more valued than others, and FWD are less so, with RWD in almost exact middle;\n",
    "- Finally, you can expect higher prices if you are selling in CA, AK, AL, TN, or UT, and lower prices if you are located in NY, OH, or PA\n",
    "\n",
    "The following is an example to test your car with my model to see the price it expects the car to sell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model to disk\n",
    "\n",
    "filename_ridge = 'Ridge.sav'\n",
    "pickle.dump(best_ridge_model, open(filename_ridge, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to check the car\n",
    "\n",
    "def predict_price(used_car):\n",
    "    model = pickle.load(open(\"Ridge.sav\", 'rb'))\n",
    "    feature_set = [\n",
    "        'manufacturer',\n",
    "        'condition',\n",
    "        'cylinders',\n",
    "        'fuel',\n",
    "        'title_status',\n",
    "        'transmission',\n",
    "        'drive',\n",
    "        'size',\n",
    "        'type',\n",
    "        'state',\n",
    "        'year',\n",
    "        'odometer'\n",
    "    ]\n",
    "    used_car_df = pd.DataFrame([used_car], columns=feature_set)\n",
    "    display(used_car_df)\n",
    "    pred_with_ridge = model.predict(used_car_df)\n",
    "    msg = f\"The Estimated Price Of The Given Car Is: ${round(pred_with_ridge[0], 2)}\"\n",
    "    return msg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Key:\n",
    "# Manufacturer, string\n",
    "# Condition, string\n",
    "# # of cylinders, int\n",
    "# Fueld type, string\n",
    "# Title status, string\n",
    "# Transmission type, string\n",
    "# Drive type, string\n",
    "# Size, string\n",
    "# Body type, string\n",
    "# State, string\n",
    "# Year of manufacturing, int\n",
    "# Odometer, int\n",
    "\n",
    "\n",
    "my_car = [\n",
    "    \"Ford\", \n",
    "    \"good\", \n",
    "    4,  \n",
    "    \"gas\", \n",
    "    \"clean\", \n",
    "    \"automatic\", \n",
    "    \"fwd\", \n",
    "    \"compact\",\n",
    "    \"hatchback\",\n",
    "    'ca',\n",
    "    2012, \n",
    "    200000\n",
    "]\n",
    "\n",
    "\n",
    "predict_price(my_car)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
